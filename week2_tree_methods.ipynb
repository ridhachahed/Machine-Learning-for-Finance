{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree methods\n",
    "\n",
    "We download and prepare some financial data (simple feature engineering and labelling).\n",
    "\n",
    "We implement and train a decision tree (first part) and boosted trees (second part) in order to try to prediction future return class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Tree\n",
    "\n",
    "1. Import the data\n",
    "2. Feature engineering and data labelling\n",
    "3. Split the data into train and test dataset\n",
    "4. Fit a decision tree model on train data\n",
    "5. Visualize the decision tree model\n",
    "6. Make predictions and evaluate the performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import the data\n",
    "\n",
    "We will import data from Yahoo! finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "data = yf.Ticker(\"TSLA\")\n",
    "df = data.history(period=\"max\")\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graphics\n",
    "\n",
    "We will use [plotnine](https://plotnine.readthedocs.io/en/stable/) as much as possible  for figures.\n",
    "\n",
    "There are many different packages for creating figures. The packages `plotnine`in Python and `ggplot2` in R both implement the [*The Grammar of Graphics*](https://www.amazon.com/Grammar-Graphics-Statistics-Computing/dp/0387245448) which will help you save a lot of time on the long run. \n",
    "\n",
    "Here is a small [tutorial](https://www.kaggle.com/residentmario/grammar-of-graphics-with-plotnine-optional/) on `plotnine`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install plotnine\n",
    "from plotnine import *\n",
    "\n",
    "(ggplot(df, aes(x='df.index', y='Close'))\n",
    " + geom_line()\n",
    " + xlab('date'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Feature engineering and data labelling\n",
    "\n",
    "We define a list of predictors using the [TA-Lib library](https://mrjbq7.github.io/ta-lib/) for technical indicators (150+ available):\n",
    "  * Average Directional Index (ADX)\n",
    "  * Relative Strength Index (RSI) \n",
    "  * Simple Moving Average (SMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## run to install ta-lib (WARNING: must install from binary)\n",
    "#!pip install talib-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import talib as ta\n",
    "import numpy as np\n",
    "\n",
    "df['ADX'] = ta.ADX(df['High'].values, df['Low'].values, df['Close'].values, timeperiod=14)\n",
    "df['RSI'] = ta.RSI(df['Close'].values, timeperiod=14)\n",
    "df['SMA'] = ta.SMA(df['Close'].values, timeperiod=20)\n",
    "\n",
    "df['Return'] = df['Close'].pct_change(1).shift(-1)\n",
    "df['target'] = np.where(df.Return > 0, 1, 0)\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove NaN values, and prepare data for tranining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "\n",
    "## feature variables\n",
    "predictors_list = ['ADX', 'RSI', 'SMA']\n",
    "X = df[predictors_list]\n",
    "X.tail()\n",
    "\n",
    "## target variable\n",
    "y = df.target\n",
    "y.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Split the data into train and test dataset\n",
    "\n",
    "Split the data into a train and a test set. \n",
    "* `stratify=y` indicates that there should be the same proportion of 1 and 0 in the train and test sets, i.e. get a more balanced dataset.\n",
    "* by default `shuffle=True` will randomly select observations rows (with the random seed set using `random_state`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Percentage of 1s in the train and test sets: %.2f and %.2f' % (np.mean(y_train)*100, np.mean(y_test)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Do you see any issues with the above train / test splitting?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Fit a decision tree model on train data\n",
    "\n",
    "We will use [scikit-learn](https://scikit-learn.org/) which is a great ML library to know. Simple with many standard algorithms available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "## create the model\n",
    "dtc = DecisionTreeClassifier(criterion='gini', max_depth=3, min_samples_leaf=5) \n",
    "\n",
    "## train the model\n",
    "dtc = dtc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## uncomment the line below for help\n",
    "# help(DecisionTreeClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Visualize the decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!sudo apt install graphviz\n",
    "#!pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import graphviz\n",
    "\n",
    "dot_data = tree.export_graphviz(dtc, out_file=None, filled=True, feature_names=predictors_list)   \n",
    "graphviz.Source(dot_data) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Make Predictions and evaluate the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make predictions on the train and test sets\n",
    "y_hat_train = dtc.predict(X_train)\n",
    "y_hat_test = dtc.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare performance on train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print('Train set report:\\n', classification_report(y_train, y_hat_train))\n",
    "print('Test set report:\\n', classification_report(y_test, y_hat_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Implement some more advanced feature engineering techniques and data labelling techniques discussed in the course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosted trees\n",
    "\n",
    "We will use a boosted trees model prepared with [TensorFlow Estimator](https://www.tensorflow.org/guide/estimator).\n",
    "\n",
    "Why? Build a model following a high-level logic.\n",
    "\n",
    "![tf-estimator](https://files.virgool.io/upload/users/11692/posts/t1molsna5wnn/mvr6hysy4acc.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will follow the model construction from [this tutorial](https://www.tensorflow.org/tutorials/estimator/boosted_trees)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the input function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "NUMERIC_COLUMNS = ['ADX', 'RSI', 'SMA']\n",
    "CATEGORICAL_COLUMNS = [] ## not used here\n",
    "\n",
    "fc = tf.feature_column\n",
    "\n",
    "## add numerical features\n",
    "feature_columns = []\n",
    "for feature_name in NUMERIC_COLUMNS:\n",
    "    feature_columns.append(fc.numeric_column(feature_name, dtype=tf.float32))\n",
    "\n",
    "## map classes to one-hot vectors\n",
    "def one_hot_cat_column(feature_name, vocab):\n",
    "    return fc.indicator_column(\n",
    "        fc.categorical_column_with_vocabulary_list(feature_name, vocab))\n",
    "\n",
    "## add categorical features\n",
    "for feature_name in CATEGORICAL_COLUMNS:\n",
    "    vocabulary = df[feature_name].unique()\n",
    "    feature_columns.append(one_hot_cat_column(feature_name, vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is one-hot encoding?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "## Example of one-hot encoding\n",
    "example = dict({'country': pd.Series('Switzerland')})\n",
    "class_fc = one_hot_cat_column('country',  {'US', 'China', 'Switzerland'})\n",
    "\n",
    "print('Feature value: \"{}\"'.format(example['country'].iloc[0]))\n",
    "print('One-hot encoded: ', tf.keras.layers.DenseFeatures([class_fc])(example).numpy())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## input_fn() maker\n",
    "def make_input_fn(X, y, n_epochs=None, shuffle=True, batch_size=len(y)):\n",
    "    def input_fn():\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((dict(X), y))\n",
    "        if shuffle:\n",
    "            dataset = dataset.shuffle(batch_size)\n",
    "        dataset = dataset.repeat(n_epochs)  \n",
    "        dataset = dataset.batch(batch_size)\n",
    "        return dataset\n",
    "    return input_fn\n",
    "\n",
    "# Training and evaluation input functions\n",
    "train_input_fn = make_input_fn(X_train, y_train)\n",
    "test_input_fn = make_input_fn(X_test, y_test, shuffle=False, n_epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and evaluate the model\n",
    "\n",
    "We will use the pre-canned TensorFlow [boosted tree](https://www.tensorflow.org/api_docs/python/tf/estimator/BoostedTreesClassifier) estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boosted trees\n",
    "nbpl = int(np.ceil(0.5 * len(y_train) / 128))\n",
    "btc = tf.estimator.BoostedTreesClassifier(feature_columns,\n",
    "                                          n_batches_per_layer=nbpl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "btc.train(train_input_fn, max_steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "result = btc.evaluate(test_input_fn)\n",
    "print(pd.Series(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data, if do not make a new input it will run all the batches and epoch\n",
    "train_input_fn_2 = make_input_fn(X_train, y_train, shuffle=False, n_epochs=1)\n",
    "results_train = btc.evaluate(train_input_fn_2)\n",
    "\n",
    "# Test data\n",
    "results_test = btc.evaluate(test_input_fn)\n",
    "\n",
    "print('Accuracy (train data): ', results_train['accuracy'])\n",
    "print('Dummy model (train data): ', results_train['accuracy_baseline'])\n",
    "print('Accuracy (test data): ', results_test['accuracy'])\n",
    "print('Dummy model (test data): ', results_test['accuracy_baseline'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make predictions, and generate reports as above\n",
    "preds_train = list(btc.predict(train_input_fn_2))\n",
    "preds_test = list(btc.predict(test_input_fn))\n",
    "y_hat_train = [pred['class_ids'][0] for pred in preds_train]\n",
    "y_hat_test = [pred['class_ids'][0] for pred in preds_test]\n",
    "\n",
    "print('Train set report:\\n', classification_report(y_train, y_hat_train))\n",
    "print('Test set report:\\n', classification_report(y_test, y_hat_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Try more advanced feature engineering techniques and data labelling.\n",
    "\n",
    "Reflect and try on what could be done to better align train and test sets performance.\n",
    "\n",
    "Compare your model performance to a simple linear model using the TensorFlow [linear classifier](https://www.tensorflow.org/api_docs/python/tf/estimator/LinearClassifier) estimator.\n",
    "\n",
    "```python\n",
    "## Linear classifier\n",
    "lc = tf.estimator.LinearClassifier(feature_columns)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
